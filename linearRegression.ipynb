{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File containing code to run linear regression algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable option to treat NAN and inf the same way\n",
    "pd.options.mode.use_inf_as_na = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "examResults = pd.read_csv(\"../data/processed/results/ug_results.csv\")\n",
    "accreditationScore = pd.read_csv(\"../data/processed/college_accreditation_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "examResults = examResults.drop(['appeared_female', 'appeared_total', 'passed_female', 'passed_total', 'first_class_passed_female', 'first_class_passed_total', 'appeared_male', 'passed_male', 'first_class_passed_male'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge exam results with accreditation score\n",
    "df = pd.merge(examResults, accreditationScore, on=[\"id\", \"name\"]).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index\n",
    "df = df.set_index([\"id\", \"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate score\n",
    "score = df[\"normalised_score\"].to_frame()\n",
    "\n",
    "# Remove score from data\n",
    "df = df.drop([\"normalised_score\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise all percentage based stats\n",
    "for column in df.columns:\n",
    "    df[column] = 0.01*df[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data for testing and training\n",
    "testing, df = np.split(df, [500])\n",
    "testingScore, score = np.split(score, [500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise random weights\n",
    "weights = pd.DataFrame(np.random.uniform(0,1,size=(df.shape[1], 1)), columns=[\"normalised_score\"])\n",
    "weights[\"index\"] = df.columns\n",
    "weights = weights.set_index([\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise error and counter\n",
    "err = 100\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate till error is less than 10%\n",
    "while abs(err) > 1:\n",
    "    # Update counter\n",
    "    counter = counter + 1\n",
    "\n",
    "    # Calculate score using weights\n",
    "    res = df@weights\n",
    "\n",
    "    # Calculate mean square error\n",
    "    diff = score[\"normalised_score\"].subtract(res[\"normalised_score\"])\n",
    "    diff = diff.to_frame()\n",
    "    diff = diff.pow(2)\n",
    "    err = diff.sum()\n",
    "    err = err.values[0]/df.shape[0]\n",
    "    err = math.sqrt(err)\n",
    "\n",
    "    # Replace cells with infinite value with max value\n",
    "    df.fillna(df.max(),inplace=True)\n",
    "    diff.fillna(diff.max(),inplace=True)\n",
    "\n",
    "    # Update weights\n",
    "    weights = weights + 0.00000001*df.T@diff\n",
    "\n",
    "    # Check if iteration limit is reached\n",
    "    if counter > 5000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print number of iterations and training error\n",
    "print(\"training iterations: \", counter)\n",
    "print(\"training err: \", err)\n",
    "\n",
    "# Print the weights\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use leaned weights on testing data\n",
    "testRes = testing@weights\n",
    "\n",
    "# Calculate testing error\n",
    "diff = testingScore[\"normalised_score\"].subtract(testRes[\"normalised_score\"])\n",
    "diff = diff.to_frame()\n",
    "diff = diff.pow(2)\n",
    "err = diff.sum()\n",
    "err = err.values[0]/testing.shape[0]\n",
    "err = math.sqrt(err)\n",
    "\n",
    "# Display testing error\n",
    "print(\"testeerr; \", err)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
